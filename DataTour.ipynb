{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\onedrive\\bureau\\translate_en_fr\\myenv\\lib\\site-packages (1.6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\user\\onedrive\\bureau\\translate_en_fr\\myenv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\onedrive\\bureau\\translate_en_fr\\myenv\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\onedrive\\bureau\\translate_en_fr\\myenv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\onedrive\\bureau\\translate_en_fr\\myenv\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE avec l'ensemble learning: 0.23\n",
      "\n",
      "Meilleurs paramètres trouvés: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "\n",
      "Top 10 des caractéristiques les plus importantes:\n",
      "                             feature  importance\n",
      "2                          promotion    0.229353\n",
      "32                      region_Rural    0.105679\n",
      "33                     region_Urbain    0.060902\n",
      "5                   stock_disponible    0.053758\n",
      "0                         Unnamed: 0    0.050505\n",
      "1                      prix_unitaire    0.048558\n",
      "8                                day    0.041814\n",
      "43      region_weather_Rural_Orageux    0.027849\n",
      "7                              month    0.025662\n",
      "45  region_weather_Urbain_Ensoleillé    0.023190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Bureau\\Translate_en_fr\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, VotingRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Charger et nettoyer les données comme précédemment\n",
    "df_train = pd.read_csv(\"https://raw.githubusercontent.com/dataafriquehub/donnee_vente/refs/heads/main/train.csv\")\n",
    "df_submission = pd.read_csv(\"https://raw.githubusercontent.com/dataafriquehub/donnee_vente/refs/heads/main/submission.csv\")\n",
    "\n",
    "# Nettoyage des données\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "# Feature Engineering avancé\n",
    "df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "df_train['year'] = df_train['date'].dt.year\n",
    "df_train['month'] = df_train['date'].dt.month\n",
    "df_train['day'] = df_train['date'].dt.day\n",
    "df_train['dayofweek'] = df_train['date'].dt.dayofweek\n",
    "df_train['is_weekend'] = df_train['date'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "df_train['quarter'] = df_train['date'].dt.quarter\n",
    "\n",
    "# Ajout d'interactions entre variables\n",
    "df_train['region_weather'] = df_train['region'] + \"_\" + df_train['condition_meteo']\n",
    "df_train['season'] = pd.cut(df_train['month'], bins=[0,3,6,9,12], labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "\n",
    "df_train.drop(['date', 'id_produit'], axis=1, inplace=True)\n",
    "\n",
    "# Encodage des variables catégoriques\n",
    "df_train = pd.get_dummies(df_train, columns=['categorie', 'marque', 'condition_meteo', 'region', \n",
    "                                            'moment_journee', 'region_weather', 'season'], drop_first=True)\n",
    "\n",
    "# Séparation des caractéristiques et de la cible\n",
    "X = df_train.drop(['quantite_vendue'], axis=1)\n",
    "y = df_train['quantite_vendue']\n",
    "\n",
    "# Normalisation des caractéristiques\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Split des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Définition des hyperparamètres pour la recherche\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Recherche des meilleurs hyperparamètres\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=params,\n",
    "                                 n_iter=20, cv=5, random_state=42, n_jobs=-1,\n",
    "                                 scoring='neg_mean_absolute_percentage_error')\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Utilisation du meilleur modèle\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Entraînement des autres modèles\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "abr = AdaBoostRegressor(random_state=42)\n",
    "\n",
    "gbr.fit(X_train, y_train)\n",
    "abr.fit(X_train, y_train)\n",
    "\n",
    "# Ensemble learning\n",
    "ensemble_model = VotingRegressor(estimators=[('rf', best_rf), ('gbr', gbr), ('abr', abr)])\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "print(f\"MAPE avec l'ensemble learning: {mean_absolute_percentage_error(y_test, y_pred):.2f}\")\n",
    "\n",
    "# Importance des caractéristiques\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 des caractéristiques les plus importantes:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Préparation des données de soumission\n",
    "submission_ids = df_submission['id_produit'].copy()\n",
    "df_submission['date'] = pd.to_datetime(df_submission['date'])\n",
    "df_submission['year'] = df_submission['date'].dt.year\n",
    "df_submission['month'] = df_submission['date'].dt.month\n",
    "df_submission['day'] = df_submission['date'].dt.day\n",
    "df_submission['dayofweek'] = df_submission['date'].dt.dayofweek\n",
    "df_submission['is_weekend'] = df_submission['date'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "df_submission['quarter'] = df_submission['date'].dt.quarter\n",
    "df_submission['region_weather'] = df_submission['region'] + \"_\" + df_submission['condition_meteo']\n",
    "df_submission['season'] = pd.cut(df_submission['month'], bins=[0,3,6,9,12], labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "\n",
    "df_submission.drop(['date', 'id_produit'], axis=1, inplace=True)\n",
    "df_submission = pd.get_dummies(df_submission, columns=['categorie', 'marque', 'condition_meteo', 'region', \n",
    "                                                      'moment_journee', 'region_weather', 'season'], drop_first=True)\n",
    "\n",
    "# Aligner les colonnes avec l'ensemble d'entraînement\n",
    "X_submission = df_submission.reindex(columns=X.columns, fill_value=0)\n",
    "X_submission_scaled = scaler.transform(X_submission)\n",
    "\n",
    "# Prédictions finales\n",
    "y_submission_pred = ensemble_model.predict(X_submission_scaled)\n",
    "\n",
    "# Création du fichier de soumission\n",
    "final_submission = pd.DataFrame({\n",
    "    'id_produit': submission_ids,\n",
    "    'quantite_vendue': y_submission_pred\n",
    "})\n",
    "\n",
    "final_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
